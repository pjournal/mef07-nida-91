[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "NIDA DONMEZ Progress Journal",
    "section": "",
    "text": "Introduction\n\nThis progress journal covers NIDA DONMEZ’s work during their term at BDA 503 Fall 2023.\nEach section is an assignment or an individual work."
  },
  {
    "objectID": "assignment1.html#about-me",
    "href": "assignment1.html#about-me",
    "title": "1  Assignment 1",
    "section": "1.1 | ABOUT ME",
    "text": "1.1 | ABOUT ME\nI am Nida Donmez, currently studying in MEF University Big Data Analytics Master’s Program 2023-24. I work as an Indirect Online Channels Account Manager in Turkish Airlines. In my field, there is big bulk of data that requires presentation, visualisation and interpretation, which surely will bring up more sophisticated insight via deeper analysis. I aim to enrich these skills and put them in practice by making use of various tools and approaches learnt during this course."
  },
  {
    "objectID": "assignment1.html#posit-pbc-youtube-channel",
    "href": "assignment1.html#posit-pbc-youtube-channel",
    "title": "1  Assignment 1",
    "section": "1.2 | POSIT PBC YOUTUBE CHANNEL",
    "text": "1.2 | POSIT PBC YOUTUBE CHANNEL\nThis is a Youtube channel created by RStudio community aiming to inform users about open-source tools for R language and data science updates, with interviews and presentations from data science professionals.\n\n1.2.1 | Leveraging R & Python in Tableau with RStudio Connect\n\n\n\nI chose to watch the video titled “Leveraging R & Python in Tableau with RStudio Connect | James Blair”.\nJames Blair is a Product Manager in Posit PBC. In this video, he presents the useful extensions of R, Python and Shiny functions for their use in Tableau. He starts with an example of implementing a machine learning model, random forest, via extensions from R and Python, but then explains that Python and R extensions might be useful not only for ML models, and also for more advanced statistical computations that Tableau is not capable of. All these extensions are possible by installing specific Tableau API packages in R and Python, and integrating them to Tableau with the extension paths created in R Studio. At the end of the video, he also presents how to provide Shiny extension. Its use is simpler, just a file version is downloaded to then be uploaded to Tableau app that is being used. At the end of the video, he illustrates an example of how the graphs created with four different tools can be displayed together in a Tableau dashboard.\nIn order to check for further resources, these extension names are:\n\nplumbertableau for R\nfastapitableau for Python\nshinytableau for Shiny"
  },
  {
    "objectID": "assignment1.html#daily-trending-youtube-videos-dataset",
    "href": "assignment1.html#daily-trending-youtube-videos-dataset",
    "title": "1  Assignment 1",
    "section": "1.3 | DAILY TRENDING YOUTUBE VIDEOS DATASET",
    "text": "1.3 | DAILY TRENDING YOUTUBE VIDEOS DATASET\nThis dataset in Kaggle contains top 50 latest trending videos on YouTube across 113 countries, and is updated daily. This dataset provides comprehensive information about the top trending videos, including daily rankings, movement trends, view counts, likes, comments, and more\nGo to Kaggle for more on dataset\n\n1.3.1 | Interpreting The Dataset With R\nBelow, I imported the library “dplyr”, then imported the file in RStudio, and applied a basic formula to list the top 10 most watched Youtube channels in Turkey today (10.11.2023):\n\nlibrary(dplyr) \n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\ndf_1 &lt;- read.csv(\"/Users/nidadonmez/Downloads/trending_yt_videos_113_countries.csv\") \ndf_1 %&gt;%\narrange(desc(view_count)) %&gt;% \n  filter(snapshot_date == \"2023-11-10\") %&gt;% \n  filter(country == \"TR\") %&gt;% \n  select(channel_name, view_count, country) %&gt;% \nhead(10)\n\n             channel_name view_count country\n1        Alan Chikin Chow   22399023      TR\n2        Marusya Outdoors   19979992      TR\n3        Celine & Michiel   14528064      TR\n4  Fabiosa Best Lifehacks   12077791      TR\n5                    SMOL   11929530      TR\n6             Alex & Ksyu    7785802      TR\n7        승비니 Seungbini    7705651      TR\n8                TWO MORE    7454832      TR\n9             ARTEMI STAR    6599492      TR\n10             Sakla Beni    4458777      TR"
  },
  {
    "objectID": "assignment1.html#relevant-r-posts",
    "href": "assignment1.html#relevant-r-posts",
    "title": "1  Assignment 1",
    "section": "1.4 | RELEVANT R POSTS",
    "text": "1.4 | RELEVANT R POSTS\n\n1.4.1 | Exploration for R Built-in Datasets\nThis post outlines that R-built-in datasets do not require any installation and can directly be called and functioned, as below:\n\nhead(mtcars, 6)\n\n                   mpg cyl disp  hp drat    wt  qsec vs am gear carb\nMazda RX4         21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\nMazda RX4 Wag     21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\nDatsun 710        22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\nHornet 4 Drive    21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\nHornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\nValiant           18.1   6  225 105 2.76 3.460 20.22  1  0    3    1\n\n\nIt is also easy to visualise the data with a histogram, below example to see the frequency of hp types:\n\nhist(mtcars$hp)\n\n\n\n\nPost source\n\n\n1.4.2 | Graphics in R\nThis post here creates a simple dataset and briefly explains the types of useful graphs that can be built out of a dataset in R, by introducing the code for each graph type. It also provides links to more detailed content and tutorials for different graph types, and a rich content of video tutorials for the package that can be used to create more advanced formats of these graphs (ggplot2).\nI hereby share the code for building a density graph as an example from the post:\n\nset.seed(123)\nx &lt;- rnorm(30)\ny &lt;- x + rnorm(30)  \nplot(density(x))   \n\n\n\n\nPost source"
  },
  {
    "objectID": "inclass1.html#preparation",
    "href": "inclass1.html#preparation",
    "title": "2  InClass1",
    "section": "2.1 | Preparation",
    "text": "2.1 | Preparation\n\n## Installing dplyr\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\n\n## Importing the dataset\nyoutube &lt;- read.csv(\"/Users/nidadonmez/Downloads/trending_yt_videos_113_countries.csv\")"
  },
  {
    "objectID": "inclass1.html#analysis-1",
    "href": "inclass1.html#analysis-1",
    "title": "2  InClass1",
    "section": "2.2 | Analysis 1",
    "text": "2.2 | Analysis 1\nHere I check the validity of the dataset by grouping the total number of records by country and filter them by randomly selected dates:\n\n## To check if each country on a given date really contains 50 videos:\nyoutube %&gt;%\n    filter(snapshot_date == \"2023-11-10\") %&gt;% \n group_by(country) %&gt;% \n  summarise(total_count =n(), .groups = \"drop\")\n\n# A tibble: 113 × 2\n   country total_count\n   &lt;chr&gt;         &lt;int&gt;\n 1 AE               50\n 2 AL               50\n 3 AM               50\n 4 AR               50\n 5 AT               50\n 6 AU               50\n 7 AZ               50\n 8 BA               50\n 9 BD               50\n10 BE               50\n# ℹ 103 more rows\n\n\n\n## To continue above analysis with another random date:\nyoutube %&gt;%\n    filter(snapshot_date == \"2023-11-05\") %&gt;% \n group_by(country) %&gt;% \n  summarise(total_count =n(), .groups = \"drop\")\n\n# A tibble: 113 × 2\n   country total_count\n   &lt;chr&gt;         &lt;int&gt;\n 1 AE               50\n 2 AL               50\n 3 AM               50\n 4 AR               50\n 5 AT               50\n 6 AU               50\n 7 AZ               50\n 8 BA               50\n 9 BD               50\n10 BE               50\n# ℹ 103 more rows"
  },
  {
    "objectID": "inclass1.html#analysis-2",
    "href": "inclass1.html#analysis-2",
    "title": "2  InClass1",
    "section": "2.3 | Analysis 2",
    "text": "2.3 | Analysis 2\nI want to bring the top 5 videos that have got the highest number of comments worldwide during the time range of the dataset:\n\nyoutube  %&gt;%\n  group_by(title) %&gt;%\nsummarise(total_comment = sum(comment_count)) %&gt;% \n  ungroup %&gt;% \n  arrange(desc(total_comment)) %&gt;% \nhead(5)\n\n# A tibble: 5 × 2\n  title                                                            total_comment\n  &lt;chr&gt;                                                                    &lt;int&gt;\n1 정국 (Jung Kook) 'Standing Next to You' Official MV                   79671285\n2 skibidi toilet 67 (part 2)                                            50070393\n3 KALAASTAR - Full Video | Honey 3.0 | Yo Yo Honey Singh & Sonaks…      44020289\n4 I Built 100 Wells In Africa                                           36163225\n5 World’s Deadliest Laser Maze!                                         32026005"
  },
  {
    "objectID": "inclass1.html#analysis-3",
    "href": "inclass1.html#analysis-3",
    "title": "2  InClass1",
    "section": "2.4 | Analysis 3",
    "text": "2.4 | Analysis 3\nTo check the engagement rates by country, I want to group the countries by the highest rate of likes out of total views during the time range of the dataset, and bring top 10 countries:\n\nyoutube  %&gt;%\n  group_by(country) %&gt;%\nsummarise(total_view = sum(view_count), like_engagement = sum(like_count)/sum(view_count)) %&gt;% \n  ungroup %&gt;% \n  arrange(desc(like_engagement)) %&gt;% \nhead(10)\n\n# A tibble: 10 × 3\n   country total_view like_engagement\n   &lt;chr&gt;        &lt;dbl&gt;           &lt;dbl&gt;\n 1 JO      1397804063          0.0683\n 2 IQ      1487839862          0.0675\n 3 LY      1580401023          0.0668\n 4 LB      1838351618          0.0664\n 5 DZ      1191019610          0.0662\n 6 YE      1682891866          0.0650\n 7 BR       785158849          0.0649\n 8 TN      1800458954          0.0648\n 9 MA      1191177698          0.0643\n10 FR       885176519          0.0643\n\n\nAnd bring last 10 countries for lowest engagement rates:\n\nyoutube  %&gt;%\n  group_by(country) %&gt;%\nsummarise(total_view = sum(view_count), like_engagement = sum(like_count)/sum(view_count)) %&gt;% \n  ungroup %&gt;% \n  arrange(like_engagement) %&gt;% \nhead(10)\n\n# A tibble: 10 × 3\n   country  total_view like_engagement\n   &lt;chr&gt;         &lt;dbl&gt;           &lt;dbl&gt;\n 1 LA      16969834067          0.0210\n 2 TZ       3709647151          0.0214\n 3 KH      27864624810          0.0216\n 4 SN      10110132491          0.0228\n 5 AL      12484143847          0.0230\n 6 MK      14753659905          0.0234\n 7 BA      10629627209          0.0235\n 8 ME      10120936040          0.0241\n 9 AM      14818966845          0.0242\n10 AZ       9488748280          0.0248"
  },
  {
    "objectID": "inclass2.html",
    "href": "inclass2.html",
    "title": "3  InClass2",
    "section": "",
    "text": "In this in-class assignment, we visualise the comparison of two different variables of our proposed datasets in Assignment 1 via a scatterplot using “ggplot2” package.\n\nlibrary(ggplot2)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n##reimport the dataset\nyoutube &lt;- read.csv(\"/Users/nidadonmez/Downloads/trending_yt_videos_113_countries.csv\") \n\nI would like to check for any relationship between the comment engagement and the like engagement in terms of views in a scatterplot:\n\n## summarise the data first to see how each variable looks\nc_l_by_country &lt;- youtube %&gt;%\n  group_by(country) %&gt;%\nsummarise(c_engagement = sum(comment_count)/sum(view_count), l_engagement = sum(like_count)/sum(view_count))\nc_l_by_country\n\n# A tibble: 113 × 3\n   country c_engagement l_engagement\n   &lt;chr&gt;          &lt;dbl&gt;        &lt;dbl&gt;\n 1 AE          0.00227        0.0487\n 2 AL          0.000116       0.0230\n 3 AM          0.000247       0.0242\n 4 AR          0.00343        0.0606\n 5 AT          0.00303        0.0567\n 6 AU          0.00262        0.0451\n 7 AZ          0.000287       0.0248\n 8 BA          0.000148       0.0235\n 9 BD          0.000820       0.0285\n10 BE          0.000530       0.0338\n# ℹ 103 more rows\n\n\nThe comment engagement rate by country can vary in terms of decimels while like engagement is in general point two decimels. In this case, it can be difficult to summarise y values around proper numbers, but we can try:\n\n##a scatterplot as below can be created. \nggplot(c_l_by_country, aes(x = c_engagement, y = l_engagement)) + geom_point() + expand_limits(y=0)\n\n\n\n##expand_limits equaled to 0 to start each row by 0 to see clearly\n\nComment rate looked very varied having values less than e-4 and e-3 on the initial rows of data, making us think that it might also include values of until e-1 decimels. However, in the summary of the scatterplot, we can see that it is proper data in between 0 to 0.003. In this case, the scatterplot brought us a clear summary where we can see a positive correlation between the comment engagement and the like engagement."
  },
  {
    "objectID": "shinyassignment.html#shiny-app-link",
    "href": "shinyassignment.html#shiny-app-link",
    "title": "4  Shiny Assignment",
    "section": "4.1 Shiny App Link:",
    "text": "4.1 Shiny App Link:\nShiny App"
  },
  {
    "objectID": "shinyassignment.html#command-line",
    "href": "shinyassignment.html#command-line",
    "title": "4  Shiny Assignment",
    "section": "4.2 Command Line",
    "text": "4.2 Command Line\nshiny::runGitHub(repo = \"pjournal/mef07-nida-91\",subdir=\"Shiny/app.R\")"
  }
]